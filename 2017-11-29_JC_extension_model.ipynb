{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import clip\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.optim import SGD, Adam\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from torch.nn.functional import softplus\n",
    "w = widgets.IntText()\n",
    "%matplotlib inline\n",
    "%run utils.py\n",
    "%load_ext Cython\n",
    "from numpy.random import permutation\n",
    "M, N = 40, 140\n",
    "\n",
    "# file to run model on\n",
    "filename = 'data/split/JC_week1_hour8_40x140.csv'\n",
    "\n",
    "def log_sum_exp(value):\n",
    "    m = torch.max(value)\n",
    "    sum_exp = torch.sum(torch.exp(value - m))\n",
    "    return m + torch.log(sum_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from itertools import permutations\n",
    "from sympy.utilities.iterables import multiset_permutations\n",
    "\n",
    "cdef int M = 40\n",
    "cdef int N = 140\n",
    "DTYPE = int\n",
    "ctypedef np.int_t DTYPE_t\n",
    "\n",
    "\n",
    "def random_path(int sx, int sy, int tx, int ty, int L):\n",
    "    \"\"\"sample L random paths from sx, sy to tx, ty\"\"\"\n",
    "    cdef int hor_dir, ver_dir, X, Y, XY\n",
    "    \n",
    "    hor_dir = (tx - sx) > 0\n",
    "    ver_dir = (ty - sy) > 0\n",
    "    \n",
    "    cdef np.ndarray[DTYPE_t, ndim=3] paths = np.zeros([M, N, L], dtype=DTYPE)\n",
    "    paths[sx,sy,:] = 1\n",
    "    \n",
    "    X = abs(tx - sx) \n",
    "    Y = abs(ty - sy) \n",
    "    XY = X + Y\n",
    "    \n",
    "    cdef np.ndarray[DTYPE_t, ndim=1] path = np.zeros(X+Y, dtype=DTYPE)\n",
    "    path[:X] = 1\n",
    "    \n",
    "    cdef int l, i, x, y\n",
    "\n",
    "    for l in range(L):\n",
    "        x, y = sx, sy\n",
    "        np.random.shuffle(path)\n",
    "        for i in range(XY):\n",
    "            if path[i]:\n",
    "                x += 2 * hor_dir - 1\n",
    "            else:\n",
    "                y += 2 * ver_dir - 1\n",
    "            paths[x,y,l] = 1\n",
    "    return paths\n",
    "\n",
    "\n",
    "# def all_paths(int sx, int sy, int tx, int ty):\n",
    "#     \"\"\"Give all paths from (sx, sy) to (tx, ty)\"\"\"\n",
    "#     cdef int hor_dir, ver_dir, X, Y, XY\n",
    "#     X = abs(tx - sx) \n",
    "#     Y = abs(ty - sy) \n",
    "#     XY = X + Y\n",
    "    \n",
    "#     hor_dir = (tx - sx) > 0\n",
    "#     ver_dir = (ty - sy) > 0\n",
    "    \n",
    "#     cdef np.ndarray[DTYPE_t, ndim=1] path = np.zeros(X+Y, dtype=DTYPE)\n",
    "#     path[:X] = 1\n",
    "#     possible_paths = list(multiset_permutations(path))\n",
    "    \n",
    "#     cdef int L = len(possible_paths)\n",
    "#     cdef np.ndarray[DTYPE_t, ndim=3] paths = np.zeros([M, N, L], dtype=DTYPE)\n",
    "#     paths[sx,sy,:] = 1\n",
    "\n",
    "#     cdef int l, i, x, y\n",
    "\n",
    "#     for l in range(L):\n",
    "#         x, y = sx, sy\n",
    "#         path = np.array(list(possible_paths[l]))\n",
    "#         for i in range(XY):\n",
    "#             if path[i]:\n",
    "#                 x += 2 * hor_dir - 1\n",
    "#             else:\n",
    "#                 y += 2 * ver_dir - 1\n",
    "#             paths[x,y,l] = 1\n",
    "#     return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.756249840075741"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(df['ty'] - df['sy']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98216f29a8b4a4b8285e5afef63e139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jiafengchen/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/jiafengchen/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/Users/jiafengchen/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e42862ba72f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                             int(tx), int(ty), L)\n\u001b[1;32m     32\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-e42862ba72f6>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(paths, t)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\"Implement the loss function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     weighted_paths = (Variable(Tensor(paths.astype(float)))\n\u001b[0m\u001b[1;32m     14\u001b[0m                               * weights.unsqueeze(-1))\n\u001b[1;32m     15\u001b[0m     \u001b[0mweight_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights = Variable((10 * torch.ones((M,N))).float(), requires_grad=True)\n",
    "\n",
    "# hyperparameters of the model\n",
    "L = 20\n",
    "s2 = 10 ** 2 # sigma2 = (10 s) ** 2\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "optimizer = Adam([weights], lr = 0.05) # using Adam since we are doing some stochastic optimization things\n",
    "num_epochs = 5\n",
    "def loss_fn(paths, t):\n",
    "    \"\"\"Implement the loss function\"\"\"\n",
    "    weighted_paths = (Variable(Tensor(paths.astype(float)))\n",
    "                              * weights.unsqueeze(-1))\n",
    "    weight_sums = weighted_paths.sum(dim=0).sum(dim=0)\n",
    "    first = (-1/(2 * L * s2) * (t - weight_sums).pow(2).sum())\n",
    "    second = - weighted_paths.sum() / L\n",
    "    third = - log_sum_exp(-weight_sums)\n",
    "    loss = -(first + second + third)\n",
    "    return loss \n",
    "\n",
    "    \n",
    "\n",
    "pbar = tqdm(total=num_epochs * len(df))\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for _, duration, sx, sy, tx, ty in (df.sample(frac=1).itertuples()):\n",
    "        pbar.update(1)\n",
    "        paths = random_path(int(sx), int(sy), int(tx), int(ty), L)\n",
    "        t = float(duration)\n",
    "        loss = loss_fn(paths, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
